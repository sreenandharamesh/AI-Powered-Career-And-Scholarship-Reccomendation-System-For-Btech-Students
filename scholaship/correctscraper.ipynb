{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2162ea75-d226-4143-af2a-4a8b6426f493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping collegedunia.com...\n",
      "Scraping https://collegedunia.com/courses/bachelor-of-technology-btech/scholarship-for-btech-students-in-india...\n",
      "Scraping https://collegedunia.com/courses/bachelor-of-technology-btech/scholarships-for-btech-students-in-kerala...\n",
      "Scraping vidhyaa.in...\n",
      "✅ Combined data (no duplicates) successfully saved to: C:\\Users\\sreen\\Desktop\\scholaship\\combined_scholarships_no_duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set up ChromeDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Function to clean text by removing extra spaces, newlines, and redundant phrases\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"N/A\"\n",
    "    # Remove extra spaces and newlines\n",
    "    text = \" \".join(text.split())\n",
    "    # Remove common redundant phrases\n",
    "    redundant_phrases = [\n",
    "        \"Below mentioned we have listed some top scholarships for B.Tech Students 2025.\",\n",
    "        \"The key objective of this scheme is to provide financial assistance to\",\n",
    "        \"This scholarship is for\",\n",
    "        \"Eligibility:\",\n",
    "        \"The scholarship aims to\",\n",
    "        \"This scheme is\",\n",
    "        \"The candidate must\",\n",
    "        \"Students must\",\n",
    "    ]\n",
    "    for phrase in redundant_phrases:\n",
    "        text = text.replace(phrase, \"\")\n",
    "    return text.strip()\n",
    "\n",
    "# Function to scrape scholarships from collegedunia.com\n",
    "def scrape_collegedunia(url):\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"table-striped\")))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    scholarships_data = {}\n",
    "\n",
    "    for table in soup.find_all('table', class_='table table-striped style_table'):\n",
    "        for row in table.find_all('tr')[1:]:  # Skip header row\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 5:  # Ensure there are enough columns\n",
    "                scholarship_name = cols[0].text.strip()\n",
    "                provider = cols[1].text.strip()\n",
    "                eligibility = clean_text(cols[2].text.strip())\n",
    "                amount = clean_text(cols[4].text.strip())\n",
    "\n",
    "                # Use scholarship name as key to avoid duplicates\n",
    "                scholarships_data[scholarship_name] = {\n",
    "                    'Scholarship Name': scholarship_name,\n",
    "                    'Provider': provider,\n",
    "                    'Eligibility': eligibility,\n",
    "                    'Amount': amount\n",
    "                }\n",
    "\n",
    "    return scholarships_data\n",
    "\n",
    "# Function to scrape scholarships from vidhyaa.in\n",
    "def scrape_vidhyaa():\n",
    "    url = \"https://www.vidhyaa.in/blog/scholarship-for-btech-students\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for JavaScript to load content\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    scholarship_sections = soup.find_all('h2')\n",
    "    scholarships_data = {}\n",
    "\n",
    "    for section in scholarship_sections:\n",
    "        scholarship_name_tag = section.find('a')\n",
    "        scholarship_name = scholarship_name_tag.text.strip() if scholarship_name_tag else None\n",
    "\n",
    "        if not scholarship_name or scholarship_name == \"N/A\":\n",
    "            continue\n",
    "\n",
    "        eligibility_section = section.find_next('p')\n",
    "        eligibility = eligibility_section.text.strip() if eligibility_section else \"N/A\"\n",
    "        eligibility = clean_text(eligibility)\n",
    "\n",
    "        # Use scholarship name as key to avoid duplicates\n",
    "        scholarships_data[scholarship_name] = {\n",
    "            'Scholarship Name': scholarship_name,\n",
    "            'Provider': 'N/A',  # vidhyaa.in does not provide this info\n",
    "            'Eligibility': eligibility,\n",
    "            'Amount': 'N/A'  # vidhyaa.in does not provide this info\n",
    "        }\n",
    "\n",
    "    return scholarships_data\n",
    "\n",
    "# Scrape data from collegedunia.com first\n",
    "collegedunia_urls = [\n",
    "    \"https://collegedunia.com/courses/bachelor-of-technology-btech/scholarship-for-btech-students-in-india\",\n",
    "    \"https://collegedunia.com/courses/bachelor-of-technology-btech/scholarships-for-btech-students-in-kerala\"\n",
    "]\n",
    "\n",
    "print(\"Scraping collegedunia.com...\")\n",
    "combined_data = {}\n",
    "for url in collegedunia_urls:\n",
    "    print(f\"Scraping {url}...\")\n",
    "    scholarships = scrape_collegedunia(url)\n",
    "    combined_data.update(scholarships)  # Add scholarships to combined data\n",
    "\n",
    "# Scrape data from vidhyaa.in\n",
    "print(\"Scraping vidhyaa.in...\")\n",
    "vidhyaa_scholarships = scrape_vidhyaa()\n",
    "\n",
    "# Add vidhyaa.in scholarships to combined data, avoiding duplicates\n",
    "for name, data in vidhyaa_scholarships.items():\n",
    "    if name not in combined_data:  # Only add if not already present\n",
    "        combined_data[name] = data\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Save combined data to CSV\n",
    "csv_filename = \"combined_scholarships_no_duplicates.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['Scholarship Name', 'Provider', 'Eligibility', 'Amount'])\n",
    "    writer.writeheader()\n",
    "    for scholarship in combined_data.values():\n",
    "        writer.writerow(scholarship)\n",
    "\n",
    "# Print CSV file path\n",
    "csv_path = os.path.abspath(csv_filename)\n",
    "print(f\"✅ Combined data (no duplicates) successfully saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c67bf09-9536-4bd3-a40f-23eac3f32d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping collegedunia.com...\n",
      "Scraping https://collegedunia.com/courses/bachelor-of-technology-btech/scholarship-for-btech-students-in-india...\n",
      "Scraping https://collegedunia.com/courses/bachelor-of-technology-btech/scholarships-for-btech-students-in-kerala...\n",
      "Scraping vidhyaa.in...\n",
      "✅ Combined data (no duplicates) successfully saved to: C:\\Users\\sreen\\Desktop\\scholaship\\combined60.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set up ChromeDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Function to clean text by removing extra spaces, newlines, and redundant phrases\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"N/A\"\n",
    "    # Remove extra spaces and newlines\n",
    "    text = \" \".join(text.split())\n",
    "    # Remove common redundant phrases\n",
    "    redundant_phrases = [\n",
    "        \"Below mentioned we have listed some top scholarships for B.Tech Students 2025.\",\n",
    "        \"The key objective of this scheme is to provide financial assistance to\",\n",
    "        \"This scholarship is for\",\n",
    "        \"Eligibility:\",\n",
    "        \"The scholarship aims to\",\n",
    "        \"This scheme is\",\n",
    "        \"The candidate must\",\n",
    "        \"Students must\",\n",
    "    ]\n",
    "    for phrase in redundant_phrases:\n",
    "        text = text.replace(phrase, \"\")\n",
    "    return text.strip()\n",
    "\n",
    "# Function to scrape scholarships from collegedunia.com\n",
    "def scrape_collegedunia(url):\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"table-striped\")))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    scholarships_data = {}\n",
    "\n",
    "    for table in soup.find_all('table', class_='table table-striped style_table'):\n",
    "        for row in table.find_all('tr')[1:]:  # Skip header row\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 5:  # Ensure there are enough columns\n",
    "                scholarship_name = cols[0].text.strip()\n",
    "                provider = cols[1].text.strip()\n",
    "                eligibility = clean_text(cols[2].text.strip())\n",
    "                amount = clean_text(cols[4].text.strip())\n",
    "\n",
    "                # Use scholarship name as key to avoid duplicates\n",
    "                scholarships_data[scholarship_name] = {\n",
    "                    'Scholarship Name': scholarship_name,\n",
    "                    'Provider': provider,\n",
    "                    'Eligibility': eligibility,\n",
    "                    'Amount': amount\n",
    "                }\n",
    "\n",
    "    return scholarships_data\n",
    "\n",
    "# Function to scrape scholarships from vidhyaa.in\n",
    "def scrape_vidhyaa():\n",
    "    url = \"https://www.vidhyaa.in/blog/scholarship-for-btech-students\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for JavaScript to load content\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    scholarship_sections = soup.find_all('h2')\n",
    "    scholarships_data = {}\n",
    "\n",
    "    for section in scholarship_sections:\n",
    "        scholarship_name_tag = section.find('a')\n",
    "        scholarship_name = scholarship_name_tag.text.strip() if scholarship_name_tag else None\n",
    "\n",
    "        if not scholarship_name or scholarship_name == \"N/A\":\n",
    "            continue\n",
    "\n",
    "        eligibility_section = section.find_next('p')\n",
    "        eligibility = eligibility_section.text.strip() if eligibility_section else \"N/A\"\n",
    "        eligibility = clean_text(eligibility)\n",
    "\n",
    "        # Use scholarship name as key to avoid duplicates\n",
    "        scholarships_data[scholarship_name] = {\n",
    "            'Scholarship Name': scholarship_name,\n",
    "            'Provider': 'N/A',  # vidhyaa.in does not provide this info\n",
    "            'Eligibility': eligibility,\n",
    "            'Amount': 'N/A'  # vidhyaa.in does not provide this info\n",
    "        }\n",
    "\n",
    "    return scholarships_data\n",
    "\n",
    "# Scrape data from collegedunia.com first\n",
    "collegedunia_urls = [\n",
    "    \"https://collegedunia.com/courses/bachelor-of-technology-btech/scholarship-for-btech-students-in-india\",\n",
    "    \"https://collegedunia.com/courses/bachelor-of-technology-btech/scholarships-for-btech-students-in-kerala\"\n",
    "]\n",
    "\n",
    "print(\"Scraping collegedunia.com...\")\n",
    "combined_data = {}\n",
    "for url in collegedunia_urls:\n",
    "    print(f\"Scraping {url}...\")\n",
    "    scholarships = scrape_collegedunia(url)\n",
    "    combined_data.update(scholarships)  # Add scholarships to combined data\n",
    "\n",
    "# Scrape data from vidhyaa.in\n",
    "print(\"Scraping vidhyaa.in...\")\n",
    "vidhyaa_scholarships = scrape_vidhyaa()\n",
    "\n",
    "# Add vidhyaa.in scholarships to combined data, avoiding duplicates\n",
    "for name , data in vidhyaa_scholarships.items():\n",
    "    if name not in combined_data:  # Only add if not already present\n",
    "        combined_data[name] = data\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Save combined data to CSV\n",
    "csv_filename = \"combined60.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['Scholarship Name', 'Provider', 'Eligibility', 'Amount'])\n",
    "    writer.writeheader()\n",
    "    for scholarship in combined_data.values():\n",
    "        writer.writerow(scholarship)\n",
    "\n",
    "# Print CSV file path\n",
    "csv_path = os.path.abspath(csv_filename)\n",
    "print(f\"✅ Combined data (no duplicates) successfully saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1803252-7fea-4a59-a2cf-645a0a19c1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
